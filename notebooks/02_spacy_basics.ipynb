{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1874c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yaskhanloo/Developer/nlp-stroke/.venv-py39/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194b2cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaskhanloo/Developer/nlp-stroke/.venv-py39/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a49170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Token Details:\n",
      "The             | POS: DET        | Dep: det             | Lemma: the\n",
      "patient         | POS: NOUN       | Dep: nsubj           | Lemma: patient\n",
      "had             | POS: VERB       | Dep: ROOT            | Lemma: have\n",
      "a               | POS: DET        | Dep: det             | Lemma: a\n",
      "right           | POS: ADV        | Dep: advmod          | Lemma: right\n",
      "-               | POS: PUNCT      | Dep: punct           | Lemma: -\n",
      "sided           | POS: ADJ        | Dep: amod            | Lemma: sided\n",
      "ischemic        | POS: ADJ        | Dep: amod            | Lemma: ischemic\n",
      "stroke          | POS: NOUN       | Dep: dobj            | Lemma: stroke\n",
      "with            | POS: ADP        | Dep: prep            | Lemma: with\n",
      "an              | POS: DET        | Dep: det             | Lemma: an\n",
      "NIHSS           | POS: ADJ        | Dep: amod            | Lemma: nihss\n",
      "score           | POS: NOUN       | Dep: pobj            | Lemma: score\n",
      "of              | POS: ADP        | Dep: prep            | Lemma: of\n",
      "8               | POS: NUM        | Dep: pobj            | Lemma: 8\n",
      "and             | POS: CCONJ      | Dep: cc              | Lemma: and\n",
      "was             | POS: AUX        | Dep: auxpass         | Lemma: be\n",
      "treated         | POS: VERB       | Dep: conj            | Lemma: treat\n",
      "with            | POS: ADP        | Dep: prep            | Lemma: with\n",
      "aspirin         | POS: NOUN       | Dep: pobj            | Lemma: aspirin\n",
      ".               | POS: PUNCT      | Dep: punct           | Lemma: .\n",
      "\n",
      "üè∑Ô∏è Named Entities:\n",
      "NIHSS                          | Label: ORG\n",
      "8                              | Label: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy's small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Clinical-style sentence\n",
    "text = \"The patient had a right-sided ischemic stroke with an NIHSS score of 8 and was treated with aspirin.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenization, POS tagging, dependency parsing\n",
    "print(\"üß© Token Details:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} | POS: {token.pos_:<10} | Dep: {token.dep_:<15} | Lemma: {token.lemma_}\")\n",
    "\n",
    "# Named Entity Recognition\n",
    "print(\"\\nüè∑Ô∏è Named Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<30} | Label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d588328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé STROKE_SIDE  | left-sided ischemic stroke\n",
      "üîé NIHSS_SCORE  | NIHSS score of 7\n",
      "üîé MEDICATION   | aspirin\n",
      "\n",
      "üßæ Extracted Data:\n",
      "{'stroke_side': 'left-sided ischemic stroke', 'nihss': 7, 'medications': ['aspirin']}\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Example clinical note\n",
    "text = \"The patient had a left-sided ischemic stroke with an NIHSS score of 7 and received aspirin.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# --- Add pattern for NIHSS score ---\n",
    "pattern_nihss = [\n",
    "    {\"LOWER\": \"nihss\"},\n",
    "    {\"LOWER\": \"score\"},\n",
    "    {\"LOWER\": \"of\"},\n",
    "    {\"LIKE_NUM\": True}\n",
    "]\n",
    "matcher.add(\"NIHSS_SCORE\", [pattern_nihss])\n",
    "\n",
    "# --- Add pattern for stroke side ---\n",
    "# Fix: Define pattern properly within the matcher.add call\n",
    "matcher.add(\"STROKE_SIDE\", [\n",
    "    [\n",
    "        {\"LOWER\": \"left\"},\n",
    "        {\"ORTH\": \"-\", \"OP\": \"?\"},  # Optional hyphen\n",
    "        {\"LOWER\": \"sided\", \"OP\": \"?\"},  # Optional \"sided\"\n",
    "        {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "        {\"LOWER\": \"stroke\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"LOWER\": \"right\"},\n",
    "        {\"ORTH\": \"-\", \"OP\": \"?\"},  # Optional hyphen\n",
    "        {\"LOWER\": \"sided\", \"OP\": \"?\"},  # Optional \"sided\"\n",
    "        {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "        {\"LOWER\": \"stroke\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"LOWER\": {\"IN\": [\"left\", \"right\"]}},\n",
    "        {\"LOWER\": \"hemisphere\"}\n",
    "    ]\n",
    "])\n",
    "\n",
    "# --- Add pattern for medication names ---\n",
    "pattern_medications = [\n",
    "    {\"LOWER\": {\"IN\": [\"aspirin\", \"clopidogrel\", \"alteplase\"]}}\n",
    "]\n",
    "matcher.add(\"MEDICATION\", [pattern_medications])\n",
    "\n",
    "# --- Apply matcher ---\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(f\"üîé {nlp.vocab.strings[match_id]:<12} | {span.text}\")\n",
    "    \n",
    "# ---- Build structured result ----\n",
    "results = {\n",
    "    \"stroke_side\": None,\n",
    "    \"nihss\": None,\n",
    "    \"medications\": []\n",
    "}\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    label = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "\n",
    "    if label == \"STROKE_SIDE\" and not results[\"stroke_side\"]:\n",
    "        results[\"stroke_side\"] = span.text\n",
    "\n",
    "    elif label == \"NIHSS_SCORE\" and not results[\"nihss\"]:\n",
    "        # Extract the number (last token)\n",
    "        for token in span:\n",
    "            if token.like_num:\n",
    "                results[\"nihss\"] = int(token.text)\n",
    "\n",
    "    elif label == \"MEDICATION\":\n",
    "        med = span.text.lower()\n",
    "        if med not in results[\"medications\"]:\n",
    "            results[\"medications\"].append(med)\n",
    "\n",
    "# Print structured results\n",
    "print(\"\\nüßæ Extracted Data:\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-stroke)",
   "language": "python",
   "name": "nlp-stroke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
